default:
  batch_size: 1024
  beta: 0.005
  buffer_size: 10240
  curiosity_enc_size: 128
  curiosity_strength: 0.01
  epsilon: 0.2
  gamma: 0.995
  hidden_units: 392
  lambd: 0.9125
  learning_rate: 0.0003
  max_steps: 1000000.0
  memory_size: 256
  normalize: false
  num_epoch: 7
  num_layers: 2
  sequence_length: 64
  summary_freq: 1000
  time_horizon: 1040
  trainer: ppo
  use_curiosity: false
  use_recurrent: false
